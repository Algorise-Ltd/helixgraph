{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEL-21 Phase 4: FastAPI Integration & Entity Linking\n",
    "\n",
    "## ğŸ¯ Phase 4 ç›®æ ‡\n",
    "1. âœ… æµ‹è¯•Phase 3è®­ç»ƒçš„æ¨¡å‹\n",
    "2. ğŸ”— å®ç°Entity Linkingï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰\n",
    "3. ğŸš€ å¼€å‘FastAPI endpoints\n",
    "4. ğŸ§ª é›†æˆæµ‹è¯•\n",
    "\n",
    "**æ³¨æ„**: æ‰€æœ‰ä»£ç åœ¨ `.py` æ–‡ä»¶ä¸­ï¼Œæ­¤notebookä»…ç”¨äºè¿è¡Œå’Œæµ‹è¯•\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Step 1: ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ é‡è¦ï¼šé¦–æ¬¡è¿è¡ŒæŒ‡å—\n",
    "\n",
    "### ç¬¬ä¸€æ¬¡ä½¿ç”¨æ­¤notebookæ—¶ï¼š\n",
    "\n",
    "1. **è¿è¡ŒCell 3**: æŒ‚è½½Google Drive\n",
    "2. **è¿è¡ŒCell 4**: åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•\n",
    "3. **è¿è¡ŒCell 5**: ä¿®å¤ä¾èµ–å†²çªï¼ˆè¿™ä¼šå®‰è£…å…¼å®¹çš„åŒ…ç‰ˆæœ¬ï¼‰\n",
    "4. **âš ï¸ å¿…é¡»é‡å¯runtime**: `Runtime` â†’ `Restart runtime`\n",
    "5. **é‡å¯åè¿è¡ŒCell 6**: éªŒè¯ç¯å¢ƒ\n",
    "6. **ç»§ç»­åç»­cells**\n",
    "\n",
    "### å·²ç»å®Œæˆsetupçš„ç”¨æˆ·ï¼š\n",
    "- è·³è¿‡Cell 5ï¼ˆä¾èµ–å®‰è£…ï¼‰\n",
    "- ç›´æ¥ä»Cell 6ï¼ˆéªŒè¯ï¼‰æˆ–Cell 7ï¼ˆæµ‹è¯•æ¨¡å‹ï¼‰å¼€å§‹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Helixgraph\n",
      "/content/drive/MyDrive/Helixgraph\n",
      "total 103\n",
      "drwx------ 2 root root  4096 Nov 21 16:44 configs\n",
      "-rw------- 1 root root  8638 Nov 21 17:00 EDUCATIONAL_SUMMARY.md\n",
      "-rw------- 1 root root  5569 Nov 23 19:56 entity_extraction.py\n",
      "-rw------- 1 root root  6357 Nov 23 19:55 entity_linking.py\n",
      "drwx------ 2 root root  4096 Nov 21 16:42 evaluation\n",
      "-rw------- 1 root root 53064 Nov 22 22:15 HEL21_NER_Training.ipynb\n",
      "drwx------ 2 root root  4096 Nov 23 19:10 models\n",
      "-rw------- 1 root root  6196 Nov 21 16:43 README.md\n",
      "drwx------ 2 root root  4096 Nov 23 19:55 scripts\n",
      "drwx------ 2 root root  4096 Nov 21 16:34 task_descriptions\n",
      "drwx------ 2 root root  4096 Nov 21 18:42 training_data\n"
     ]
    }
   ],
   "source": [
    "# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•\n",
    "%cd /content/drive/MyDrive/Helixgraph\n",
    "\n",
    "# éªŒè¯ç›®å½•ç»“æ„\n",
    "!pwd\n",
    "!ls -la nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Helixgraph\n",
      "/content/drive/MyDrive/Helixgraph\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ æœ€ç»ˆä¿®å¤æ–¹æ¡ˆ - å¼ºåˆ¶é‡æ–°å®‰è£…å¹¶é™çº§thinc\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ”¥ Final Fix - Force reinstall with compatible thinc\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: å®Œå…¨ç§»é™¤spacyç›¸å…³åŒ…\n",
    "print(\"\\nğŸ“¦ Step 1: Completely removing spacy ecosystem...\")\n",
    "packages = [\n",
    "    \"spacy\", \"spacy-transformers\", \"spacy-legacy\", \"spacy-loggers\", \n",
    "    \"thinc\", \"catalogue\", \"srsly\", \"wasabi\", \"confection\",\n",
    "    \"pydantic\", \"pydantic-core\", \"fastapi\"\n",
    "]\n",
    "for pkg in packages:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], \n",
    "                   capture_output=True)\n",
    "print(\"   âœ… Removed all packages\")\n",
    "\n",
    "# Step 2: æ¸…é™¤ç¼“å­˜\n",
    "print(\"\\nğŸ—‘ï¸  Step 2: Clearing ALL caches...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"cache\", \"purge\"], capture_output=True)\n",
    "subprocess.run([\"rm\", \"-rf\", \"/root/.cache/pip\"], capture_output=True)\n",
    "print(\"   âœ… Caches cleared\")\n",
    "\n",
    "# Step 3: ä½¿ç”¨force-reinstallå®‰è£…\n",
    "print(\"\\nğŸ“¥ Step 3: Force reinstalling with specific versions...\")\n",
    "install_sequence = [\n",
    "    # åŸºç¡€ä¾èµ–\n",
    "    [\"pip\", \"install\", \"--force-reinstall\", \"--no-cache-dir\", \"pydantic==2.6.0\", \"pydantic-core==2.16.1\"],\n",
    "    \n",
    "    # spaCyä¾èµ–ï¼ˆæŒ‡å®šå…¼å®¹ç‰ˆæœ¬ï¼‰\n",
    "    [\"pip\", \"install\", \"--force-reinstall\", \"--no-cache-dir\", \n",
    "     \"catalogue==2.0.10\", \"srsly==2.4.8\", \"wasabi==1.1.2\", \"confection==0.1.4\"],\n",
    "    \n",
    "    # thincï¼ˆä½¿ç”¨ç¨æ—©ç‰ˆæœ¬ï¼Œå¯èƒ½æ›´ç¨³å®šï¼‰\n",
    "    [\"pip\", \"install\", \"--force-reinstall\", \"--no-cache-dir\", \"thinc==8.2.3\"],\n",
    "    \n",
    "    # spaCyæ ¸å¿ƒå’Œæ‰©å±•\n",
    "    [\"pip\", \"install\", \"--force-reinstall\", \"--no-cache-dir\", \n",
    "     \"spacy-legacy==3.0.12\", \"spacy-loggers==1.0.5\"],\n",
    "    [\"pip\", \"install\", \"--force-reinstall\", \"--no-cache-dir\", \"spacy==3.7.4\"],\n",
    "    [\"pip\", \"install\", \"--force-reinstall\", \"--no-cache-dir\", \"spacy-transformers==1.3.5\"],\n",
    "    \n",
    "    # FastAPI\n",
    "    [\"pip\", \"install\", \"--no-cache-dir\", \"fastapi==0.109.0\", \"uvicorn[standard]==0.27.0\"],\n",
    "    \n",
    "    # å…¶ä»–å·¥å…·\n",
    "    [\"pip\", \"install\", \"--no-cache-dir\", \n",
    "     \"fuzzywuzzy\", \"python-Levenshtein\", \"nest-asyncio\", \"pytest\", \"httpx\"]\n",
    "]\n",
    "\n",
    "for i, cmd in enumerate(install_sequence, 1):\n",
    "    print(f\"\\n   [{i}/{len(install_sequence)}] {' '.join(cmd[2:5])}...\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"      âœ… Success\")\n",
    "    else:\n",
    "        print(f\"      âš ï¸  Warning (may be OK)\")\n",
    "\n",
    "# Step 4: éªŒè¯\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ” Quick verification...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = subprocess.run([sys.executable, \"-c\", \n",
    "    \"import spacy; import pydantic; print(f'spaCy: {spacy.__version__}'); print(f'pydantic: {pydantic.__version__}')\"],\n",
    "    capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(result.stdout)\n",
    "    print(\"\\nâœ… Basic imports work!\")\n",
    "else:\n",
    "    print(result.stderr[:300])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âš ï¸  MUST RESTART RUNTIME NOW!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nRuntime â†’ Restart runtime\")\n",
    "print(\"\\nIf this still fails after restart, we need to use Python 3.10\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ” Verifying installation...\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¦ Checking installed versions:\n",
      "   fastapi                                  0.109.0\n",
      "   opentelemetry-instrumentation-fastapi    0.59b0\n",
      "   pydantic                                 2.6.0\n",
      "   pydantic_core                            2.16.1\n",
      "   pydantic-settings                        2.1.0\n",
      "   spacy                                    3.7.4\n",
      "   spacy-alignments                         0.9.2\n",
      "   spacy-legacy                             3.0.12\n",
      "   spacy-loggers                            1.0.5\n",
      "   spacy-transformers                       1.3.5\n",
      "   thinc                                    8.2.5\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª Testing imports...\n",
      "================================================================================\n",
      "\n",
      "âŒ Unexpected error: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'\n",
      "\n",
      "âš ï¸  Error type: TypeError\n",
      "\n",
      "This suggests spaCy/pydantic are still incompatible.\n",
      "See the versions listed above - they should be:\n",
      "   spacy: 3.7.4\n",
      "   pydantic: 2.6.0 or 2.6.x\n"
     ]
    }
   ],
   "source": [
    "# âœ… éªŒè¯ç¯å¢ƒ (è¿è¡Œæ­¤cellå‰è¯·å…ˆé‡å¯runtime)\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ” Verifying installation...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# å…ˆæ£€æŸ¥å®‰è£…çš„ç‰ˆæœ¬\n",
    "print(\"\\nğŸ“¦ Checking installed versions:\")\n",
    "import subprocess\n",
    "result = subprocess.run([\"pip\", \"list\"], capture_output=True, text=True)\n",
    "for line in result.stdout.split('\\n'):\n",
    "    if any(pkg in line.lower() for pkg in ['spacy', 'pydantic', 'fastapi', 'thinc']):\n",
    "        print(f\"   {line}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ§ª Testing imports...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    import pydantic\n",
    "    import fastapi\n",
    "    from fuzzywuzzy import fuzz\n",
    "    \n",
    "    print(f\"\\nâœ… spaCy version: {spacy.__version__}\")\n",
    "    print(f\"âœ… pydantic version: {pydantic.__version__}\")\n",
    "    print(f\"âœ… FastAPI version: {fastapi.__version__}\")\n",
    "    print(f\"âœ… fuzzywuzzy imported successfully\")\n",
    "    \n",
    "    # Try to actually use spacy (this is where the error happens)\n",
    "    print(\"\\nğŸ”¬ Testing spaCy functionality...\")\n",
    "    from spacy.tokens import Doc\n",
    "    print(\"âœ… spaCy.tokens.Doc imported successfully\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ‰ All dependencies loaded successfully!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nYou can now proceed to test the model.\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\\nâŒ Import error: {e}\")\n",
    "    print(\"\\nâš ï¸  Please check the installed versions above.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Unexpected error: {e}\")\n",
    "    print(f\"\\nâš ï¸  Error type: {type(e).__name__}\")\n",
    "    print(\"\\nThis suggests spaCy/pydantic are still incompatible.\")\n",
    "    print(\"See the versions listed above - they should be:\")\n",
    "    print(\"   spacy: 3.7.4\")\n",
    "    print(\"   pydantic: 2.6.0 or 2.6.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
      "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
      "python3-distutils set to manually installed.\n",
      "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
      "python3.10 set to manually installed.\n",
      "The following NEW packages will be installed:\n",
      "  python3.10-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
      "Need to get 508 kB of archives.\n",
      "After this operation, 523 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.11 [508 kB]\n",
      "Fetched 508 kB in 1s (638 kB/s)         \n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package python3.10-dev.\n",
      "(Reading database ... 121713 files and directories currently installed.)\n",
      "Preparing to unpack .../python3.10-dev_3.10.12-1~22.04.11_amd64.deb ...\n",
      "Unpacking python3.10-dev (3.10.12-1~22.04.11) ...\n",
      "Setting up python3.10-dev (3.10.12-1~22.04.11) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [pip]\u001b[32m2/3\u001b[0m [pip]ptools]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pip-25.3 setuptools-80.9.0 wheel-0.45.1\n",
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…Python 3.10\n",
    "!sudo apt-get update -qq\n",
    "!sudo apt-get install -y python3.10 python3.10-dev python3.10-distutils\n",
    "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10\n",
    "!python3.10 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/Helixgraph/nlp/scripts/test_trained_model.py\", line 8, in <module>\n",
      "    import spacy\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/__init__.py\", line 13, in <module>\n",
      "    from . import pipeline  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/pipeline/__init__.py\", line 1, in <module>\n",
      "    from .attributeruler import AttributeRuler\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/pipeline/attributeruler.py\", line 8, in <module>\n",
      "    from ..language import Language\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/language.py\", line 43, in <module>\n",
      "    from .pipe_analysis import analyze_pipes, print_pipe_analysis, validate_attrs\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/pipe_analysis.py\", line 6, in <module>\n",
      "    from .tokens import Doc, Span, Token\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/tokens/__init__.py\", line 1, in <module>\n",
      "    from ._serialize import DocBin\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/tokens/_serialize.py\", line 14, in <module>\n",
      "    from ..vocab import Vocab\n",
      "  File \"spacy/vocab.pyx\", line 1, in init spacy.vocab\n",
      "  File \"spacy/tokens/doc.pyx\", line 49, in init spacy.tokens.doc\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/schemas.py\", line 195, in <module>\n",
      "    class TokenPatternString(BaseModel):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/main.py\", line 286, in __new__\n",
      "    cls.__try_update_forward_refs__()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/main.py\", line 807, in __try_update_forward_refs__\n",
      "    update_model_forward_refs(cls, cls.__fields__.values(), cls.__config__.json_encoders, localns, (NameError,))\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 554, in update_model_forward_refs\n",
      "    update_field_forward_refs(f, globalns=globalns, localns=localns)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 529, in update_field_forward_refs\n",
      "    update_field_forward_refs(sub_f, globalns=globalns, localns=localns)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 520, in update_field_forward_refs\n",
      "    field.type_ = evaluate_forwardref(field.type_, globalns, localns or None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 66, in evaluate_forwardref\n",
      "    return cast(Any, type_)._evaluate(globalns, localns, set())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'\n"
     ]
    }
   ],
   "source": [
    "!python nlp/scripts/test_trained_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— Step 3: Entity Linkingå¼€å‘ä¸æµ‹è¯•\n",
    "\n",
    "ä»£ç æ–‡ä»¶: `nlp/entity_linking.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/Helixgraph/nlp/scripts/test_entity_linking.py\", line 16, in <module>\n",
      "    import spacy\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/__init__.py\", line 13, in <module>\n",
      "    from . import pipeline  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/pipeline/__init__.py\", line 1, in <module>\n",
      "    from .attributeruler import AttributeRuler\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/pipeline/attributeruler.py\", line 8, in <module>\n",
      "    from ..language import Language\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/language.py\", line 43, in <module>\n",
      "    from .pipe_analysis import analyze_pipes, print_pipe_analysis, validate_attrs\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/pipe_analysis.py\", line 6, in <module>\n",
      "    from .tokens import Doc, Span, Token\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/tokens/__init__.py\", line 1, in <module>\n",
      "    from ._serialize import DocBin\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/tokens/_serialize.py\", line 14, in <module>\n",
      "    from ..vocab import Vocab\n",
      "  File \"spacy/vocab.pyx\", line 1, in init spacy.vocab\n",
      "  File \"spacy/tokens/doc.pyx\", line 49, in init spacy.tokens.doc\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/spacy/schemas.py\", line 195, in <module>\n",
      "    class TokenPatternString(BaseModel):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/main.py\", line 286, in __new__\n",
      "    cls.__try_update_forward_refs__()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/main.py\", line 807, in __try_update_forward_refs__\n",
      "    update_model_forward_refs(cls, cls.__fields__.values(), cls.__config__.json_encoders, localns, (NameError,))\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 554, in update_model_forward_refs\n",
      "    update_field_forward_refs(f, globalns=globalns, localns=localns)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 529, in update_field_forward_refs\n",
      "    update_field_forward_refs(sub_f, globalns=globalns, localns=localns)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 520, in update_field_forward_refs\n",
      "    field.type_ = evaluate_forwardref(field.type_, globalns, localns or None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pydantic/v1/typing.py\", line 66, in evaluate_forwardref\n",
      "    return cast(Any, type_)._evaluate(globalns, localns, set())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•Entity Linking\n",
    "!python nlp/scripts/test_entity_linking.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 4: FastAPIåº”ç”¨å¼€å‘\n",
    "\n",
    "ä»£ç æ–‡ä»¶: `api/main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯åŠ¨FastAPIæœåŠ¡å™¨ (åœ¨åå°è¿è¡Œ)\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ä½¿ç”¨nohupåœ¨åå°è¿è¡Œ\n",
    "!nohup uvicorn api.main:app --host 0.0.0.0 --port 8000 > api.log 2>&1 &\n",
    "\n",
    "print(\"ğŸš€ FastAPI server starting...\")\n",
    "print(\"Check logs: !tail -f api.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹APIæ—¥å¿—\n",
    "!tail -20 api.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•APIå¥åº·æ£€æŸ¥\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/health\")\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ Step 5: è®¾ç½®Cloudflare Tunnel (å¯é€‰)\n",
    "\n",
    "å¦‚æœéœ€è¦å¤–éƒ¨è®¿é—®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ngrokåˆ›å»ºtunnel\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# åˆ›å»ºtunnelåˆ°FastAPI\n",
    "public_url = ngrok.connect(8000)\n",
    "print(f\"\\nğŸŒ Public URL: {public_url}\")\n",
    "print(f\"\\nTest with: curl {public_url}/health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 6: é›†æˆæµ‹è¯•\n",
    "\n",
    "è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œpytestæµ‹è¯•\n",
    "!pytest tests/ -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œç‰¹å®šæµ‹è¯•\n",
    "!pytest tests/test_entity_linking.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 7: æ‰‹åŠ¨æµ‹è¯•API Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•NERæå–\n",
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/api/extract-entities\",\n",
    "    json={\"text\": \"Tech Solutions Ltd submitted PO-2024-001 for the Spring Launch campaign.\"}\n",
    ")\n",
    "\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(f\"Entities: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•Entity Linking\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/api/link-entities\",\n",
    "    json={\n",
    "        \"text\": \"Acme Corp submitted invoice INV-123456\",\n",
    "        \"entities\": [\n",
    "            {\"text\": \"Acme Corp\", \"label\": \"SUPPLIER\", \"start\": 0, \"end\": 9},\n",
    "            {\"text\": \"INV-123456\", \"label\": \"INVOICE\", \"start\": 29, \"end\": 39}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Linked entities: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›‘ Step 8: åœæ­¢æœåŠ¡å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœæ­¢FastAPIæœåŠ¡å™¨\n",
    "!pkill -f \"uvicorn api.main:app\"\n",
    "print(\"âœ… Server stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ å¼€å‘ç¬”è®°\n",
    "\n",
    "### æ–‡ä»¶ç»“æ„\n",
    "```\n",
    "nlp/\n",
    "â”œâ”€â”€ entity_linking.py          # Entity linkingå®ç°\n",
    "â”œâ”€â”€ entity_extraction.py       # RAG helper\n",
    "â””â”€â”€ scripts/\n",
    "    â”œâ”€â”€ test_trained_model.py  # æ¨¡å‹æµ‹è¯•\n",
    "    â””â”€â”€ test_entity_linking.py # Entity linkingæµ‹è¯•\n",
    "\n",
    "api/\n",
    "â”œâ”€â”€ main.py                    # FastAPIåº”ç”¨\n",
    "â”œâ”€â”€ config.py                  # é…ç½®\n",
    "â”œâ”€â”€ database.py                # Neo4jè¿æ¥\n",
    "â””â”€â”€ endpoints/\n",
    "    â”œâ”€â”€ ner.py                 # NER endpoints\n",
    "    â””â”€â”€ fixed_queries.py       # 4ä¸ªå›ºå®šæŸ¥è¯¢\n",
    "\n",
    "tests/\n",
    "â”œâ”€â”€ test_entity_linking.py\n",
    "â”œâ”€â”€ test_api.py\n",
    "â””â”€â”€ test_integration.py\n",
    "```\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "- [ ] å®ŒæˆEntity Linkingå®ç°\n",
    "- [ ] åˆ›å»ºFastAPIåŸºç¡€æ¡†æ¶\n",
    "- [ ] å®ç°4ä¸ªå›ºå®šæŸ¥è¯¢\n",
    "- [ ] ä¸Sun (Neo4j) å’Œ Mert (RAG) é›†æˆ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
